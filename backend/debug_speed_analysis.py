#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•è®¢å•é€Ÿåº¦åˆ†æ
åˆ†æä¸ºä»€ä¹ˆæ‰€æœ‰è®¢å•éƒ½æ˜¾ç¤ºä¸¥é‡æ‹¥å µçš„é—®é¢˜
"""

import pandas as pd
import numpy as np
import math
from datetime import datetime
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from detect.traffic_visualization.data_processor import TrafficDataProcessor
from detect.traffic_visualization.road_analysis_engine import RoadAnalysisEngine

def debug_speed_analysis():
    """è°ƒè¯•é€Ÿåº¦åˆ†æ"""
    print("=" * 60)
    print("è°ƒè¯•è®¢å•é€Ÿåº¦åˆ†æ - æ–°ç‰ˆæœ¬")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®å¤„ç†å™¨
    data_processor = TrafficDataProcessor()
    
    # ä½¿ç”¨2013-09-12çš„æ•°æ®è¿›è¡Œæµ‹è¯•
    start_time = 1379001600  # 2013-09-12 16:00:00
    end_time = 1379005200    # 2013-09-12 17:00:00
    
    print(f"åŠ è½½æ•°æ®: {datetime.fromtimestamp(start_time)} åˆ° {datetime.fromtimestamp(end_time)}")
    
    # åŠ è½½æ•°æ®
    df = data_processor.load_data(start_time, end_time)
    
    if df.empty:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è½¨è¿¹æ•°æ®")
    
    # æ ‡å‡†åŒ–æ•°æ®åˆ—å
    if 'COMMADDR' in df.columns:
        df['vehicle_id'] = df['COMMADDR']
    if 'UTC' in df.columns:
        df['timestamp'] = df['UTC']
    if 'LAT' in df.columns and 'LON' in df.columns:
        df['latitude'] = df['LAT'] / 1e5
        df['longitude'] = df['LON'] / 1e5
    
    print(f"æ•°æ®èŒƒå›´:")
    print(f"  - è½¦è¾†æ•°: {df['vehicle_id'].nunique()}")
    print(f"  - æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(float(df['timestamp'].min()))} åˆ° {datetime.fromtimestamp(float(df['timestamp'].max()))}")
    print(f"  - çº¬åº¦èŒƒå›´: {df['latitude'].min():.6f} åˆ° {df['latitude'].max():.6f}")
    print(f"  - ç»åº¦èŒƒå›´: {df['longitude'].min():.6f} åˆ° {df['longitude'].max():.6f}")
    
    # åˆ›å»ºè·¯æ®µåˆ†æå¼•æ“
    road_engine = RoadAnalysisEngine()
    
    # ä½¿ç”¨æ–°çš„è®¢å•æå–é€»è¾‘
    print("\n" + "=" * 60)
    print("ä½¿ç”¨æ–°çš„è®¢å•æå–é€»è¾‘")
    print("=" * 60)
    
    try:
        # è¿›è¡Œè®¢å•é€Ÿåº¦åˆ†æ
        speed_analysis = road_engine.analyze_order_based_road_speed(
            df,
            include_short_medium_only=True,
            spatial_resolution=0.001,
            min_orders_per_location=5,
            congestion_threshold={
                "free": 20,      # >20km/h ä¸ºç•…é€š (é™ä½é˜ˆå€¼)
                "moderate": 10,  # 10-20km/h ä¸ºç¼“æ…¢ (é™ä½é˜ˆå€¼)
                "heavy": 5,      # 5-10km/h ä¸ºæ‹¥å µ (é™ä½é˜ˆå€¼)
                "jam": 0         # <5km/h ä¸ºä¸¥é‡æ‹¥å µ (é™ä½é˜ˆå€¼)
            }
        )
        
        print(f"âœ… æˆåŠŸå®Œæˆé€Ÿåº¦åˆ†æ")
        print(f"åˆ†æç»“æœ:")
        print(f"  - æ€»åˆ†æä½ç½®: {len(speed_analysis.speed_data)}")
        print(f"  - çƒ­åŠ›å›¾ç‚¹æ•°: {len(speed_analysis.heatmap_data)}")
        
        if speed_analysis.speed_data:
            speeds = [data.avg_speed for data in speed_analysis.speed_data]
            print(f"  - å¹³å‡é€Ÿåº¦: {np.mean(speeds):.2f} km/h")
            print(f"  - æœ€å°é€Ÿåº¦: {min(speeds):.2f} km/h")
            print(f"  - æœ€å¤§é€Ÿåº¦: {max(speeds):.2f} km/h")
            
            # æ‹¥å µç­‰çº§åˆ†å¸ƒ
            congestion_counts = {}
            for data in speed_analysis.speed_data:
                level = data.congestion_level
                congestion_counts[level] = congestion_counts.get(level, 0) + 1
            
            print(f"\næ‹¥å µç­‰çº§åˆ†å¸ƒ (ç»¼åˆç®—æ³•):")
            for level, count in congestion_counts.items():
                percentage = count / len(speed_analysis.speed_data) * 100
                print(f"  {level}: {count} ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºè®¢å•æ•°é‡åˆ†å¸ƒ
            order_counts = [data.order_count for data in speed_analysis.speed_data]
            print(f"\nè®¢å•å¯†åº¦ç»Ÿè®¡:")
            print(f"  - å¹³å‡æ¯ç½‘æ ¼è®¢å•æ•°: {np.mean(order_counts):.1f}")
            print(f"  - æœ€å°è®¢å•æ•°: {min(order_counts)}")
            print(f"  - æœ€å¤§è®¢å•æ•°: {max(order_counts)}")
            
            # è®¡ç®—å®é™…çš„è®¢å•å¯†åº¦å’Œæ—¶é—´å¯†åº¦
            spatial_resolution = 0.001
            grid_area_km2 = (spatial_resolution * 111) ** 2
            
            actual_densities = []
            time_densities = []
            
            for data in speed_analysis.speed_data:
                order_density = data.order_count / grid_area_km2
                actual_densities.append(order_density)
                # å‡è®¾1å°æ—¶æ—¶é—´çª—å£
                time_density = data.order_count / 1.0  # è®¢å•æ•°/å°æ—¶
                time_densities.append(time_density)
            
            print(f"\nå®é™…å¯†åº¦åˆ†æ:")
            print(f"  - å¹³å‡è®¢å•å¯†åº¦: {np.mean(actual_densities):.1f} è®¢å•/kmÂ²")
            print(f"  - æœ€å°è®¢å•å¯†åº¦: {min(actual_densities):.1f} è®¢å•/kmÂ²")
            print(f"  - æœ€å¤§è®¢å•å¯†åº¦: {max(actual_densities):.1f} è®¢å•/kmÂ²")
            print(f"  - å¹³å‡æ—¶é—´å¯†åº¦: {np.mean(time_densities):.1f} è®¢å•/å°æ—¶")
            print(f"  - æœ€å°æ—¶é—´å¯†åº¦: {min(time_densities):.1f} è®¢å•/å°æ—¶")
            print(f"  - æœ€å¤§æ—¶é—´å¯†åº¦: {max(time_densities):.1f} è®¢å•/å°æ—¶")
            
            # åˆ†æå¯†åº¦åˆ†å¸ƒ
            low_density_count = len([d for d in actual_densities if d <= 150])
            medium_density_count = len([d for d in actual_densities if 150 < d <= 400])
            high_density_count = len([d for d in actual_densities if d > 400])
            
            print(f"\nå¯†åº¦åˆ†å¸ƒåˆ†æ:")
            print(f"  - ä½å¯†åº¦åŒºåŸŸ (â‰¤150): {low_density_count} ({low_density_count/len(actual_densities)*100:.1f}%)")
            print(f"  - ä¸­å¯†åº¦åŒºåŸŸ (150-400): {medium_density_count} ({medium_density_count/len(actual_densities)*100:.1f}%)")
            print(f"  - é«˜å¯†åº¦åŒºåŸŸ (>400): {high_density_count} ({high_density_count/len(actual_densities)*100:.1f}%)")
            
            # åˆ†ææ—¶é—´å¯†åº¦åˆ†å¸ƒ
            low_time_density_count = len([d for d in time_densities if d <= 15])
            medium_time_density_count = len([d for d in time_densities if 15 < d <= 40])
            high_time_density_count = len([d for d in time_densities if d > 40])
            
            print(f"\næ—¶é—´å¯†åº¦åˆ†å¸ƒåˆ†æ:")
            print(f"  - ä½é¢‘ç‡åŒºåŸŸ (â‰¤15): {low_time_density_count} ({low_time_density_count/len(time_densities)*100:.1f}%)")
            print(f"  - ä¸­é¢‘ç‡åŒºåŸŸ (15-40): {medium_time_density_count} ({medium_time_density_count/len(time_densities)*100:.1f}%)")
            print(f"  - é«˜é¢‘ç‡åŒºåŸŸ (>40): {high_time_density_count} ({high_time_density_count/len(time_densities)*100:.1f}%)")
            
            # æ˜¾ç¤ºç½®ä¿¡åº¦åˆ†å¸ƒ
            confidence_scores = [data.confidence_score for data in speed_analysis.speed_data]
            print(f"\nç½®ä¿¡åº¦ç»Ÿè®¡:")
            print(f"  - å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidence_scores):.3f}")
            print(f"  - é«˜ç½®ä¿¡åº¦ä½ç½® (>0.5): {len([c for c in confidence_scores if c > 0.5])}")
        
        # æ˜¾ç¤ºæ‹¥å µæ‘˜è¦
        if speed_analysis.congestion_summary:
            print(f"\næ‹¥å µæ‘˜è¦ (ç»¼åˆç®—æ³•):")
            summary = speed_analysis.congestion_summary
            
            if 'total_analysis_locations' in summary:
                print(f"  - æ€»åˆ†æä½ç½®: {summary['total_analysis_locations']}")
            
            if 'overall_avg_speed' in summary:
                print(f"  - æ•´ä½“å¹³å‡é€Ÿåº¦: {summary['overall_avg_speed']:.2f} km/h")
            
            if 'congestion_distribution' in summary:
                print(f"  - æ‹¥å µåˆ†å¸ƒ:")
                for level, info in summary['congestion_distribution'].items():
                    print(f"    {level}: {info['count']} ({info['percentage']:.1f}%)")
            
            if 'total_orders_analyzed' in summary:
                print(f"  - æ€»è®¢å•æ•°: {summary['total_orders_analyzed']}")
        
        # åˆ†ææ”¹è¿›æ•ˆæœ
        print("\n" + "=" * 60)
        print("ç»¼åˆç®—æ³•æ”¹è¿›æ•ˆæœåˆ†æ")
        print("=" * 60)
        
        if speed_analysis.speed_data:
            avg_speed = np.mean([data.avg_speed for data in speed_analysis.speed_data])
            
            print(f"å¹³å‡é€Ÿåº¦: {avg_speed:.2f} km/h")
            
            if avg_speed > 15:
                print("âœ… é€Ÿåº¦åˆ†æåˆç†")
            elif avg_speed > 10:
                print("ğŸ”„ é€Ÿåº¦åä½ä½†å¯æ¥å—")
            else:
                print("âš ï¸  é€Ÿåº¦ä»ç„¶åä½")
            
            # æ£€æŸ¥æ‹¥å µç­‰çº§åˆ†å¸ƒæ˜¯å¦æ›´åˆç†
            jam_percentage = congestion_counts.get('jam', 0) / len(speed_analysis.speed_data) * 100
            free_percentage = congestion_counts.get('free', 0) / len(speed_analysis.speed_data) * 100
            
            print(f"æ‹¥å µç­‰çº§åˆ†å¸ƒ:")
            print(f"  - ä¸¥é‡æ‹¥å µæ¯”ä¾‹: {jam_percentage:.1f}%")
            print(f"  - ç•…é€šæ¯”ä¾‹: {free_percentage:.1f}%")
            
            if jam_percentage < 30:
                print("âœ… ä¸¥é‡æ‹¥å µæ¯”ä¾‹åˆç†")
            elif jam_percentage < 50:
                print("ğŸ”„ ä¸¥é‡æ‹¥å µæ¯”ä¾‹æœ‰æ‰€æ”¹å–„")
            else:
                print("âŒ ä¸¥é‡æ‹¥å µæ¯”ä¾‹ä»ç„¶è¿‡é«˜")
            
            if free_percentage > 10:
                print("âœ… æœ‰ç•…é€šåŒºåŸŸï¼Œåˆ†å¸ƒæ›´åˆç†")
            elif free_percentage > 0:
                print("ğŸ”„ æœ‰å°‘é‡ç•…é€šåŒºåŸŸ")
            else:
                print("âŒ æ²¡æœ‰ç•…é€šåŒºåŸŸ")
            
            # ç»¼åˆè¯„ä»·
            if jam_percentage < 30 and free_percentage > 10:
                print("\nğŸ‰ ç»¼åˆç®—æ³•æ•ˆæœä¼˜ç§€ï¼æ‹¥å µç­‰çº§åˆ†å¸ƒåˆç†")
            elif jam_percentage < 50 and (free_percentage > 0 or congestion_counts.get('moderate', 0) > 0):
                print("\nğŸ‘ ç»¼åˆç®—æ³•æ•ˆæœè‰¯å¥½ï¼Œæ¯”å•çº¯é€Ÿåº¦åˆ¤æ–­æ›´å‡†ç¡®")
            else:
                print("\nğŸ”§ ç»¼åˆç®—æ³•æœ‰æ”¹å–„ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
            
    except Exception as e:
        print(f"âŒ é€Ÿåº¦åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_speed_analysis() 