#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜å¹¶é‡æ–°è¿è¡Œé¢„å¤„ç†
"""

import os
import sys
import shutil
from datetime import datetime

def clean_partial_files():
    """æ¸…ç†éƒ¨åˆ†ç”Ÿæˆçš„æ–‡ä»¶"""
    print("ğŸ§¹ æ¸…ç†éƒ¨åˆ†ç”Ÿæˆçš„é¢„å¤„ç†æ–‡ä»¶")
    print("=" * 40)
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    processed_dir = os.path.join(current_dir, 'data', 'processed')
    indexes_dir = os.path.join(current_dir, 'data', 'indexes')
    
    cleaned_files = 0
    
    # æ¸…ç†processedç›®å½•
    if os.path.exists(processed_dir):
        for filename in os.listdir(processed_dir):
            if filename.endswith('.parquet'):
                file_path = os.path.join(processed_dir, filename)
                try:
                    os.remove(file_path)
                    print(f"   åˆ é™¤: processed/{filename}")
                    cleaned_files += 1
                except Exception as e:
                    print(f"   âŒ åˆ é™¤å¤±è´¥: {filename} - {e}")
    
    # æ¸…ç†indexesç›®å½•
    if os.path.exists(indexes_dir):
        for filename in os.listdir(indexes_dir):
            if filename.endswith('.json'):
                file_path = os.path.join(indexes_dir, filename)
                try:
                    os.remove(file_path)
                    print(f"   åˆ é™¤: indexes/{filename}")
                    cleaned_files += 1
                except Exception as e:
                    print(f"   âŒ åˆ é™¤å¤±è´¥: {filename} - {e}")
    
    print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_files} ä¸ªæ–‡ä»¶")
    return True

def verify_fix():
    """éªŒè¯ä¿®å¤æ˜¯å¦æœ‰æ•ˆ"""
    print("\nğŸ” éªŒè¯JSONåºåˆ—åŒ–ä¿®å¤")
    print("=" * 30)
    
    try:
        # å¯¼å…¥ä¿®å¤åçš„é¢„å¤„ç†å™¨
        sys.path.insert(0, os.path.dirname(__file__))
        from data_preprocessor_cleaned import convert_numpy_types
        
        print("âœ… å¯¼å…¥convert_numpy_typeså‡½æ•°æˆåŠŸ")
        
        # æµ‹è¯•numpyç±»å‹è½¬æ¢
        import numpy as np
        
        test_data = {
            'int64_value': np.int64(12345),
            'float64_value': np.float64(123.456),
            'array_value': np.array([1, 2, 3]),
            'nested_dict': {
                'nested_int': np.int32(789),
                'normal_value': 'test_string'
            }
        }
        
        print("ğŸ§ª æµ‹è¯•numpyç±»å‹è½¬æ¢...")
        converted = convert_numpy_types(test_data)
        
        # éªŒè¯è½¬æ¢ç»“æœ
        import json
        json_str = json.dumps(converted)  # è¿™åº”è¯¥ä¸ä¼šå‡ºé”™
        
        print("âœ… JSONåºåˆ—åŒ–æµ‹è¯•é€šè¿‡")
        print(f"   è½¬æ¢å‰ç±»å‹: {type(test_data['int64_value'])}")
        print(f"   è½¬æ¢åç±»å‹: {type(converted['int64_value'])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_fixed_preprocessing():
    """è¿è¡Œä¿®å¤åçš„é¢„å¤„ç†"""
    print("\nğŸš€ è¿è¡Œä¿®å¤åçš„é¢„å¤„ç†")
    print("=" * 35)
    
    try:
        from data_preprocessor_cleaned import CleanedTrafficDataPreprocessor
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = CleanedTrafficDataPreprocessor()
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        cleaned_files = preprocessor._get_cleaned_csv_files()
        if not cleaned_files:
            print("âŒ æœªæ‰¾åˆ°æ¸…æ´—åçš„æ•°æ®æ–‡ä»¶")
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(cleaned_files)} ä¸ªæ¸…æ´—åæ•°æ®æ–‡ä»¶")
        
        # å¼€å§‹é¢„å¤„ç†
        print("\nå¼€å§‹é¢„å¤„ç†...")
        start_time = datetime.now()
        
        preprocessor.preprocess_all_data()
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"\nâ±ï¸ é¢„å¤„ç†è€—æ—¶: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
        print("âœ… é¢„å¤„ç†å®Œæˆ!")
        
        return True
        
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def verify_results():
    """éªŒè¯é¢„å¤„ç†ç»“æœ"""
    print("\nğŸ“Š éªŒè¯é¢„å¤„ç†ç»“æœ")
    print("=" * 25)
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    processed_dir = os.path.join(current_dir, 'data', 'processed')
    indexes_dir = os.path.join(current_dir, 'data', 'indexes')
    
    success = True
    
    # æ£€æŸ¥processedæ–‡ä»¶
    if os.path.exists(processed_dir):
        parquet_files = [f for f in os.listdir(processed_dir) if f.endswith('.parquet')]
        print(f"âœ… ç”Ÿæˆ {len(parquet_files)} ä¸ªå°æ—¶æ•°æ®æ–‡ä»¶")
        
        if len(parquet_files) == 0:
            print("âŒ æœªç”Ÿæˆå°æ—¶æ•°æ®æ–‡ä»¶")
            success = False
    else:
        print("âŒ processedç›®å½•ä¸å­˜åœ¨")
        success = False
    
    # æ£€æŸ¥indexesæ–‡ä»¶
    if os.path.exists(indexes_dir):
        json_files = [f for f in os.listdir(indexes_dir) if f.endswith('.json')]
        print(f"âœ… ç”Ÿæˆ {len(json_files)} ä¸ªç´¢å¼•æ–‡ä»¶")
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = ['vehicle_index.json', 'data_summary.json']
        for key_file in key_files:
            if key_file in json_files:
                print(f"   âœ… {key_file}")
                
                # éªŒè¯JSONæ–‡ä»¶å¯ä»¥æ­£å¸¸è¯»å–
                try:
                    import json
                    with open(os.path.join(indexes_dir, key_file), 'r') as f:
                        data = json.load(f)
                    print(f"      ğŸ“Š å¤§å°: {len(data)} é¡¹")
                except Exception as e:
                    print(f"      âŒ è¯»å–å¤±è´¥: {e}")
                    success = False
            else:
                print(f"   âŒ ç¼ºå°‘ {key_file}")
                success = False
        
        if len(json_files) == 0:
            print("âŒ æœªç”Ÿæˆç´¢å¼•æ–‡ä»¶")
            success = False
    else:
        print("âŒ indexesç›®å½•ä¸å­˜åœ¨")
        success = False
    
    return success

def test_fast_loader():
    """æµ‹è¯•å¿«é€ŸåŠ è½½å™¨"""
    print("\nâš¡ æµ‹è¯•å¿«é€ŸåŠ è½½å™¨")
    print("=" * 20)
    
    try:
        from data_preprocessor_cleaned import EnhancedFastTrafficDataLoader
        
        loader = EnhancedFastTrafficDataLoader()
        
        # è·å–æ•°æ®æ¦‚è¦
        summary = loader.get_data_summary()
        if summary:
            print("âœ… æ•°æ®æ¦‚è¦åŠ è½½æˆåŠŸ")
            print(f"   æ€»è®°å½•æ•°: {summary.get('total_records', 0):,}")
            print(f"   æ€»è½¦è¾†æ•°: {summary.get('total_vehicles', 0):,}")
            print(f"   æ—¶é—´è·¨åº¦: {summary.get('total_hours', 0)} å°æ—¶")
            
            # æµ‹è¯•å¿«é€ŸæŸ¥è¯¢
            time_range = summary.get('time_range', {})
            if time_range.get('start'):
                test_start = time_range['start']
                test_end = test_start + 3600  # 1å°æ—¶
                
                print(f"\nğŸ§ª æµ‹è¯•å¿«é€ŸæŸ¥è¯¢ (1å°æ—¶æ•°æ®)...")
                import time
                start_time = time.time()
                
                test_data = loader.fast_load_data(test_start, test_end)
                
                end_time = time.time()
                query_time = (end_time - start_time) * 1000  # æ¯«ç§’
                
                print(f"   æŸ¥è¯¢è€—æ—¶: {query_time:.1f} æ¯«ç§’")
                print(f"   è¿”å›è®°å½•: {len(test_data):,} æ¡")
                
                if query_time < 5000:  # 5ç§’å†…
                    print("   âœ… æŸ¥è¯¢æ€§èƒ½è‰¯å¥½")
                else:
                    print("   âš ï¸ æŸ¥è¯¢æ€§èƒ½ä¸€èˆ¬")
                
                return True
        else:
            print("âŒ æ•°æ®æ¦‚è¦åŠ è½½å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å¿«é€ŸåŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    print("ğŸ”§ JSONåºåˆ—åŒ–é—®é¢˜ä¿®å¤å’Œé¢„å¤„ç†é‡è¿è¡Œ")
    print("=" * 60)
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # æ­¥éª¤1: æ¸…ç†éƒ¨åˆ†æ–‡ä»¶
    if not clean_partial_files():
        print("\nâŒ æ¸…ç†å¤±è´¥")
        return False
    
    # æ­¥éª¤2: éªŒè¯ä¿®å¤
    if not verify_fix():
        print("\nâŒ ä¿®å¤éªŒè¯å¤±è´¥")
        return False
    
    # æ­¥éª¤3: é‡æ–°è¿è¡Œé¢„å¤„ç†
    if not run_fixed_preprocessing():
        print("\nâŒ é¢„å¤„ç†å¤±è´¥")
        return False
    
    # æ­¥éª¤4: éªŒè¯ç»“æœ
    if not verify_results():
        print("\nâŒ ç»“æœéªŒè¯å¤±è´¥")
        return False
    
    # æ­¥éª¤5: æµ‹è¯•å¿«é€ŸåŠ è½½å™¨
    if not test_fast_loader():
        print("\nâš ï¸ å¿«é€ŸåŠ è½½å™¨æµ‹è¯•å¤±è´¥ï¼Œä½†é¢„å¤„ç†å·²å®Œæˆ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ä¿®å¤å’Œé¢„å¤„ç†å®Œæˆ!")
    print("=" * 60)
    
    print("âœ… ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
    print("   ğŸ“ data/")
    print("   â”œâ”€â”€ ğŸ“ cleaned/        (æ¸…æ´—ååŸå§‹æ•°æ®)")
    print("   â”œâ”€â”€ ğŸ“ processed/      (æŒ‰å°æ—¶åˆ†ç‰‡çš„Parquetæ–‡ä»¶)")
    print("   â””â”€â”€ ğŸ“ indexes/        (å¿«é€ŸæŸ¥è¯¢ç´¢å¼•)")
    
    print("\nğŸš€ ç°åœ¨å¯ä»¥äº«å—é«˜é€ŸæŸ¥è¯¢:")
    print("   - TrafficDataProcessor å°†è‡ªåŠ¨ä½¿ç”¨é¢„å¤„ç†æ•°æ®")
    print("   - æŸ¥è¯¢é€Ÿåº¦æå‡ 10-100 å€")
    print("   - å‰ç«¯å“åº”ä»åˆ†é’Ÿçº§å˜ä¸ºç§’çº§")
    
    print("\nğŸ’¡ é‡å¯åç«¯æœåŠ¡:")
    print("   cd backend")
    print("   uvicorn main:app --reload")
    
    return True

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nâœ… ä¿®å¤å’Œé¢„å¤„ç†æˆåŠŸ!")
        exit(0)
    else:
        print(f"\nâŒ ä¿®å¤å’Œé¢„å¤„ç†å¤±è´¥!")
        exit(1)