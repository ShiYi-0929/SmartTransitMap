#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿è¡Œæ¸…æ´—åæ•°æ®çš„é¢„å¤„ç†è„šæœ¬
ç”Ÿæˆindexeså’Œprocessedæ–‡ä»¶å¤¹ï¼Œç”¨äºé«˜æ•ˆæŸ¥è¯¢
"""

import os
import sys
import time
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def main():
    print("ğŸš€ æ¸…æ´—åäº¤é€šæ•°æ®é¢„å¤„ç†å™¨")
    print("=" * 60)
    print(f"å½“å‰ç›®å½•: {current_dir}")
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    try:
        # å¯¼å…¥é¢„å¤„ç†å™¨
        from data_preprocessor_cleaned import CleanedTrafficDataPreprocessor, EnhancedFastTrafficDataLoader
        
        # æ£€æŸ¥æ¸…æ´—åæ•°æ®
        data_dir = os.path.join(current_dir, 'data', 'cleaned')
        print(f"æ¸…æ´—åæ•°æ®ç›®å½•: {data_dir}")
        
        if not os.path.exists(data_dir):
            print("âŒ æ¸…æ´—åæ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼")
            print(f"è¯·ç¡®ä¿ {data_dir} ç›®å½•å­˜åœ¨ä¸”åŒ…å«æ¸…æ´—åçš„CSVæ–‡ä»¶")
            return False
        
        # æ£€æŸ¥æ¸…æ´—åçš„CSVæ–‡ä»¶
        csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
        if not csv_files:
            print("âŒ æ¸…æ´—åæ•°æ®ç›®å½•ä¸­æ²¡æœ‰CSVæ–‡ä»¶ï¼")
            print(f"è¯·ç¡®ä¿ {data_dir} ç›®å½•ä¸­æœ‰æ¸…æ´—åçš„æ•°æ®æ–‡ä»¶")
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªæ¸…æ´—åçš„CSVæ–‡ä»¶:")
        total_size = 0
        for csv_file in csv_files:
            file_path = os.path.join(data_dir, csv_file)
            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            total_size += file_size
            print(f"   ğŸ“„ {csv_file}: {file_size:.1f} MB")
        
        print(f"ğŸ“Š æ€»æ•°æ®é‡: {total_size:.1f} MB")
        print()
        
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        response = input("æ˜¯å¦å¼€å§‹é¢„å¤„ç†ï¼Ÿè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´... (Y/n): ")
        if response.lower() == 'n':
            print("âŒ ç”¨æˆ·å–æ¶ˆé¢„å¤„ç†")
            return False
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        print("\n" + "=" * 60)
        print("1ï¸âƒ£ åˆå§‹åŒ–é¢„å¤„ç†å™¨")
        print("=" * 60)
        
        preprocessor = CleanedTrafficDataPreprocessor()
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†ç°æœ‰æ•°æ®
        processed_dir = os.path.join(current_dir, 'data', 'processed')
        indexes_dir = os.path.join(current_dir, 'data', 'indexes')
        
        existing_processed = os.path.exists(processed_dir) and len(os.listdir(processed_dir)) > 0
        existing_indexes = os.path.exists(indexes_dir) and len(os.listdir(indexes_dir)) > 0
        
        if existing_processed or existing_indexes:
            print(f"\nâš ï¸ å‘ç°ç°æœ‰çš„é¢„å¤„ç†æ•°æ®:")
            if existing_processed:
                processed_files = len([f for f in os.listdir(processed_dir) if f.endswith('.parquet')])
                print(f"   ğŸ“ processedç›®å½•: {processed_files} ä¸ªparquetæ–‡ä»¶")
            if existing_indexes:
                index_files = len([f for f in os.listdir(indexes_dir) if f.endswith('.json')])
                print(f"   ğŸ“ indexesç›®å½•: {index_files} ä¸ªç´¢å¼•æ–‡ä»¶")
            
            clean_response = input("\næ˜¯å¦æ¸…ç†ç°æœ‰æ•°æ®é‡æ–°ç”Ÿæˆï¼Ÿ(y/N): ")
            if clean_response.lower() == 'y':
                print("\nğŸ§¹ æ¸…ç†ç°æœ‰é¢„å¤„ç†æ•°æ®...")
                preprocessor.clean_existing_preprocessed_data()
        
        # å¼€å§‹é¢„å¤„ç†
        print("\n" + "=" * 60)
        print("2ï¸âƒ£ å¼€å§‹æ•°æ®é¢„å¤„ç†")
        print("=" * 60)
        
        start_time = time.time()
        preprocessor.preprocess_all_data()
        end_time = time.time()
        
        processing_time = end_time - start_time
        print(f"\nâ±ï¸ é¢„å¤„ç†è€—æ—¶: {processing_time:.1f} ç§’ ({processing_time/60:.1f} åˆ†é’Ÿ)")
        
        # éªŒè¯é¢„å¤„ç†ç»“æœ
        print("\n" + "=" * 60)
        print("3ï¸âƒ£ éªŒè¯é¢„å¤„ç†ç»“æœ")
        print("=" * 60)
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        if os.path.exists(processed_dir):
            parquet_files = [f for f in os.listdir(processed_dir) if f.endswith('.parquet')]
            print(f"âœ… ç”Ÿæˆ {len(parquet_files)} ä¸ªå°æ—¶æ•°æ®æ–‡ä»¶ (processed/)")
        else:
            print("âŒ processedç›®å½•æœªç”Ÿæˆ")
            return False
        
        if os.path.exists(indexes_dir):
            json_files = [f for f in os.listdir(indexes_dir) if f.endswith('.json')]
            print(f"âœ… ç”Ÿæˆ {len(json_files)} ä¸ªç´¢å¼•æ–‡ä»¶ (indexes/)")
            
            # æ˜¾ç¤ºå…³é”®ç´¢å¼•æ–‡ä»¶
            key_indexes = ['vehicle_index.json', 'data_summary.json']
            for key_file in key_indexes:
                if key_file in [f for f in os.listdir(indexes_dir)]:
                    print(f"   ğŸ“‹ {key_file} âœ…")
                else:
                    print(f"   ğŸ“‹ {key_file} âŒ")
        else:
            print("âŒ indexesç›®å½•æœªç”Ÿæˆ")
            return False
        
        # æµ‹è¯•å¿«é€ŸåŠ è½½å™¨
        print("\n" + "=" * 60)
        print("4ï¸âƒ£ æµ‹è¯•å¢å¼ºç‰ˆå¿«é€ŸåŠ è½½å™¨")
        print("=" * 60)
        
        try:
            loader = EnhancedFastTrafficDataLoader()
            summary = loader.get_data_summary()
            
            if summary:
                print("ğŸ“Š æ•°æ®æ¦‚è¦ç»Ÿè®¡:")
                print(f"   æ€»è®°å½•æ•°: {summary.get('total_records', 0):,}")
                print(f"   æ€»è½¦è¾†æ•°: {summary.get('total_vehicles', 0):,}")
                print(f"   æ—¶é—´è·¨åº¦: {summary.get('total_hours', 0)} å°æ—¶")
                
                # åæ ‡èŒƒå›´
                coord_range = summary.get('coordinate_range', {})
                if coord_range.get('lat_min'):
                    print(f"   åæ ‡èŒƒå›´: çº¬åº¦ {coord_range['lat_min']:.4f}~{coord_range['lat_max']:.4f}, "
                          f"ç»åº¦ {coord_range['lng_min']:.4f}~{coord_range['lng_max']:.4f}")
                
                # æ—¶é—´èŒƒå›´
                time_range = summary.get('time_range', {})
                if time_range.get('start'):
                    start_dt = datetime.fromtimestamp(time_range['start'])
                    end_dt = datetime.fromtimestamp(time_range['end'])
                    print(f"   æ—¶é—´èŒƒå›´: {start_dt} ~ {end_dt}")
                
                # å¿«é€ŸæŸ¥è¯¢æµ‹è¯•
                if time_range.get('start'):
                    print(f"\nğŸ§ª å¿«é€ŸæŸ¥è¯¢æµ‹è¯•:")
                    test_start = time_range['start']
                    test_end = test_start + 3600  # 1å°æ—¶
                    
                    test_start_time = time.time()
                    test_data = loader.fast_load_data(test_start, test_end)
                    test_end_time = time.time()
                    
                    print(f"   æŸ¥è¯¢è€—æ—¶: {(test_end_time - test_start_time)*1000:.1f} æ¯«ç§’")
                    print(f"   è¿”å›è®°å½•: {len(test_data):,} æ¡")
                    
                    if len(test_data) > 0:
                        print(f"   æ ·æœ¬æ•°æ®å­—æ®µ: {list(test_data.columns)}")
            
            print("âœ… å¿«é€ŸåŠ è½½å™¨æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ å¿«é€ŸåŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
            return False
        
        # å®Œæˆ
        print("\n" + "=" * 60)
        print("ğŸ‰ é¢„å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        
        print("âœ… ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„:")
        print("   ğŸ“ data/")
        print("   â”œâ”€â”€ ğŸ“ cleaned/        (æ¸…æ´—ååŸå§‹æ•°æ®)")
        print("   â”œâ”€â”€ ğŸ“ processed/      (æŒ‰å°æ—¶åˆ†ç‰‡çš„Parquetæ–‡ä»¶)")
        print("   â””â”€â”€ ğŸ“ indexes/        (å¿«é€ŸæŸ¥è¯¢ç´¢å¼•)")
        
        print("\nğŸš€ ç°åœ¨TrafficDataProcessorå°†è‡ªåŠ¨ä½¿ç”¨é¢„å¤„ç†æ•°æ®ï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡10-100å€ï¼")
        print("\nğŸ’¡ å¯ä»¥é‡å¯åç«¯æœåŠ¡æ¥ä½“éªŒé«˜é€ŸæŸ¥è¯¢:")
        print("   cd backend")
        print("   uvicorn main:app --reload")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿data_preprocessor_cleaned.pyæ–‡ä»¶å­˜åœ¨ä¸”å¯å¯¼å…¥")
        return False
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nâœ… é¢„å¤„ç†æˆåŠŸå®Œæˆï¼")
        exit(0)
    else:
        print(f"\nâŒ é¢„å¤„ç†å¤±è´¥!")
        exit(1)